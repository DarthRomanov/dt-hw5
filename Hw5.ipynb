{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Збір даних\n",
    "\n",
    "Перш за все, потрібно зібрати дані з акселерометра мобільного телефону.\n",
    "<center><img src=\"image.png\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "activities = ['idle', 'running', 'stairs', 'walking']\n",
    "data_collections = []\n",
    "\n",
    "for index, activity in enumerate(activities, start=1):\n",
    "    activity_path = Path('data') / activity  \n",
    "    csv_files = list(activity_path.glob('*.csv'))  \n",
    "    df = pd.concat((pd.read_csv(file) for file in csv_files), ignore_index=True)\n",
    "    df['activity'] = activity\n",
    "    data_collections.append(df)\n",
    "\n",
    "data = pd.concat(data_collections, ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренування на вихідних нормалізованих данних\n",
    "\n",
    "В якості характеристик візьмемо показники з акселерометра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['accelerometer_X', 'accelerometer_Y', 'accelerometer_Z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормалізація даних\n",
    "\n",
    "Тренування на ненормаліованих даних займає чимало часу. Вхідні дані нормалізуються так, щоб їхнє середнє значення дорівнювало нулю, а стандартне відхилення - одиниці. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "data_to_normalize = data[features]\n",
    "\n",
    "# Нормалізація даних\n",
    "normalized_data = scaler.fit_transform(data_to_normalize)\n",
    "\n",
    "# Заміна вихідних даних нормалізованими даними\n",
    "ndata = data.copy()\n",
    "ndata[features] = normalized_data\n",
    "ndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Розділяємо дані\n",
    "\n",
    "Розділяємо датасет на навчальний і тестовий набори"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[features], data[\"activity\"],\n",
    "    test_size=0.3,\n",
    "    stratify=ndata[\"activity\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Навчаємо за допомогою алгоритму SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Навчаємо за допомогою алгоритму випадкового лісу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100)\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Порівнюємо точність результатів\n",
    "\n",
    "Визначаємо точність моделей на тестовому наборі та порівнюємо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_svm = model_svm.score(X_test, y_test)\n",
    "score_rf = model_rf.score(X_test, y_test)\n",
    "\n",
    "print(f\"Точність моделі SVM: {score_svm:.3f}\")\n",
    "print(f\"Точність моделі випадкового лісу: {score_rf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пргнозування"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_svm = model_svm.predict(X_test)\n",
    "y_predicted_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Побудуємо матрицю помилок (`confusion matrix`). \n",
    "\n",
    "Матрицю помилок - це таблиця, яку використовують для оцінювання продуктивності класифікаційної моделі. Вона дає змогу порівняти фактичні та передбачені класифікатором мітки для кожного об'єкта в тестовій вибірці."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_svm = confusion_matrix(y_test, y_predicted_svm)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_predicted_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "classifiers = [\"SVM\", \"Random Forest\"]\n",
    "confusion_matrices = [conf_matrix_svm, conf_matrix_rf]\n",
    "\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    sns.heatmap(\n",
    "        confusion_matrices[i],\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Reds',\n",
    "        xticklabels=activities,\n",
    "        yticklabels=activities,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    axes[i].set_title(f\"Confusion Matrix for {classifier} Classifier\")\n",
    "    axes[i].set_xlabel(\"Predicted activity\")\n",
    "    axes[i].set_ylabel(\"True activity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренування на підготовленних даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вибираємо ознаки\n",
    "\n",
    "В [статті](https://www.sciencedirect.com/science/article/pii/S1877050916322153) [1] пропонується обрати наступні часові ознаки (таблиця 3). Як пишуть автори, їхні результати показують, що найбільш репрезентативні ознаки отримані з часового представлення сигналу акселерометра. Ознаки, витягнуті з сигналів по осях $x$ і $y$ є більш релевантними, ніж ознаки по осі $z$ при визначенні активності. \n",
    "\n",
    "| Name                          | Axis |\n",
    "| ----------------------------- | ---- |\n",
    "| Maximum Value                 |   x  |\n",
    "| Minimum Value                 |   x  |\n",
    "| Entropy                       |   x  |\n",
    "| Interquartile Range           |   x  |\n",
    "| Maximum Value                 |   y  |\n",
    "| Index of Minimum Value        |   y  |\n",
    "| Mean of Absolute Deviation    |   y  |\n",
    "| Median                        |   y  |\n",
    "| Skewness                      |   y  |\n",
    "| Standard Deviation            |   y  |\n",
    "| Root Mean Square Error        |   y  |\n",
    "| Skewness                      |   z  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Створення необхідних функцій"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(data):\n",
    "    \"\"\"Calculates the interquartile range (IQR) of a dataset.\n",
    "\n",
    "    The IQR is the difference between the 75th and 25th percentiles of the data,\n",
    "    and is a measure of the spread of the middle 50% of the data.\n",
    "\n",
    "    Args:\n",
    "        data: A NumPy array or Pandas Series containing the data.\n",
    "\n",
    "    Returns:\n",
    "        The IQR of the data.\n",
    "    \"\"\"\n",
    "    sorted_data = np.sort(data)\n",
    "    \n",
    "    Q1 = np.percentile(sorted_data, 25)\n",
    "    Q3 = np.percentile(sorted_data, 75)\n",
    "    \n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    return IQR\n",
    "  \n",
    "def argmin(data):\n",
    "    \"\"\"Returns the index of the minimum value in a dataset.\n",
    "\n",
    "    Args:\n",
    "        data: A NumPy array or Pandas Series containing the data.\n",
    "\n",
    "    Returns:\n",
    "        The index of the minimum value in the data.\n",
    "    \"\"\"\n",
    "    return np.argmin(data)\n",
    "\n",
    "def entropy(column_data):\n",
    "    \"\"\"Calculates the entropy of a column of data.\n",
    "\n",
    "    Entropy is a measure of uncertainty or randomness in a set of data. It is calculated as follows:\n",
    "\n",
    "    ```\n",
    "    H = -sum(pk * log2(pk))\n",
    "    ```\n",
    "\n",
    "    where pk is the probability of each value in the data set.\n",
    "\n",
    "    Args:\n",
    "        column_data: A NumPy array or Pandas Series containing the data.\n",
    "\n",
    "    Returns:\n",
    "        The entropy of the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    hist, bins = np.histogram(column_data, bins='auto')\n",
    "    probs = hist / len(column_data)\n",
    "\n",
    "    probs = probs[probs > 0]\n",
    "\n",
    "    entropy = -np.sum(probs * np.log2(probs))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def mad(data):\n",
    "    \"\"\"Calculates the median absolute deviation (MAD) of a dataset.\n",
    "\n",
    "    The MAD is a measure of the spread of the data, and is calculated as the median of the absolute deviations from the median. It is a more robust measure of spread than the standard deviation, as it is less sensitive to outliers.\n",
    "\n",
    "    Args:\n",
    "        data: A NumPy array or Pandas Series containing the data.\n",
    "\n",
    "    Returns:\n",
    "        The MAD of the data.\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "    \n",
    "    absolute_deviations = np.abs(data - mean)\n",
    "    \n",
    "    mad = np.mean(absolute_deviations)\n",
    "    \n",
    "    return mad\n",
    "\n",
    "def rmse(data):\n",
    "    \"\"\"Calculates the root mean square error (RMSE) of a dataset.\n",
    "\n",
    "    The RMSE is a measure of the average difference between the actual values in the dataset and the predicted values. It is calculated as follows:\n",
    "\n",
    "    ```\n",
    "    RMSE = sqrt(mean((y_true - y_pred)**2))\n",
    "    \n",
    "\n",
    "    where:\n",
    "\n",
    "    * `y_true` is the actual values in the dataset\n",
    "    * `y_pred` is the predicted values\n",
    "\n",
    "    The RMSE is a good measure of fit for regression models, and is often used to evaluate the performance of a model on a held-out test set.\n",
    "\n",
    "    Args:\n",
    "        data: A NumPy array or Pandas Series containing the data.\n",
    "\n",
    "    Returns:\n",
    "        The RMSE of the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    mean = np.mean(data)\n",
    "    \n",
    "    squared_errors = [(x - mean) ** 2 for x in data]\n",
    "    \n",
    "    rmse = np.sqrt(np.mean(squared_errors))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Створення датасету на основі ознак, вказанних в статті"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_aggregations = {\n",
    "    'accelerometer_X': [\"max\", \"min\", entropy, iqr],\n",
    "    'accelerometer_Y': [\"max\", argmin, mad, \"median\", \"skew\", \"std\", rmse],\n",
    "    'accelerometer_Z': [\"skew\"]\n",
    "}\n",
    "\n",
    "data_tdf = pd.DataFrame()\n",
    "\n",
    "\n",
    "for axis, functions in axis_aggregations.items():\n",
    "    axis_data = ndata.groupby([\"activity\", ndata.index // 30])[axis].agg(functions)\n",
    "    \n",
    "    multiindex = pd.MultiIndex.from_product([[axis], axis_data.columns])\n",
    "    \n",
    "    axis_data.columns = multiindex\n",
    "    data_tdf = pd.concat([data_tdf, axis_data], axis=1)\n",
    "\n",
    "data_tdf.reset_index(level=0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Утворений датасет на основі ознак таблиці 3 статті [1]\n",
    "\n",
    "data_tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Розділяємо датасет на навчальний і тестовий набори"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_tdf[features], data_tdf[\"activity\"],\n",
    "    test_size=0.3,\n",
    "    stratify=data_tdf[\"activity\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Навчаємо за домомогою алгоритму `SVN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Навчаємо за домомогою алгоритму `random forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100)\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визначаємо точність моделей на тестовому наборі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_svm = model_svm.score(X_test, y_test)\n",
    "score_rf = model_rf.score(X_test, y_test)\n",
    "\n",
    "print(f\"Точність моделі SVM: {score_svm:.3f}\")\n",
    "print(f\"Точність моделі випадкового лісу: {score_rf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пргнозування"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_svm = model_svm.predict(X_test)\n",
    "y_predicted_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Побудуємо матрицю помилок `confusion matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_svm = confusion_matrix(y_test, y_predicted_svm)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_predicted_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "classifiers = [\"SVM\", \"Random Forest\"]\n",
    "confusion_matrices = [conf_matrix_svm, conf_matrix_rf]\n",
    "\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    sns.heatmap(\n",
    "        confusion_matrices[i],\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Greens',\n",
    "        xticklabels=activities,\n",
    "        yticklabels=activities,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    axes[i].set_title(f\"Confusion Matrix for {classifier} Classifier\")\n",
    "    axes[i].set_xlabel(\"Predicted activity\")\n",
    "    axes[i].set_ylabel(\"True activity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Як видно, класифікатор `SVM` на тестових даних помилився у всіх 49 випадках, класифікувавши ходіння по сходах (`stairs`) як прогулянку (`walking`). Тобто, зовсім не розпізнає ходіння по сходах.\n",
    "\n",
    "- Класифікатор `ramdom forest` на тестових даних помилився лише в 5 випадках, класифікувавши ходіння по сходах (`stairs`) як прогулянку (`walking`). \n",
    "\n",
    "Слід сказати. що набір даних для `stairs` був найменшим з усіх інших. Тому тут бажано було б набрати більше даних, тоді може `SVM` дав би кращі результати."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результати та висновки\n",
    "\n",
    "\n",
    "1. Для навчання алгоритму `SVN` на __вихідних ознаках__ (показах акселерометра по трьох осях) потрібно близько 20 хвилин на стандартному комп'ютері. Навчання на вихідних ознаках (показах акселерометра по трьох осях) спричиняє довге навчання, оскільки алгоритм `SVN` має велику кількість параметрів, які потрібно оптимізувати. Це пов'язано з тим, що алгоритм `SVN` намагається знайти оптимальну підмножину ознак, яка найкраще класифікує дані. У випадку з даними про рух людини, які мають багато шуму і невизначеності, це може бути дуже складним завданням.\n",
    "\n",
    "2. Навчання на __нормалізованих ознаках__ акселерометра по трьох осях зменшує час навчання алгоритму `SVN` близько 4 хвилин. Навчання на нормалізованих величинах акселерометра по трьох осях дає значний виграш при навчання по методу `SVN`. Нормалізація показів акселерометра по трьох осях усуває масштабування, яке може призвести до переваги одних ознак над іншими. Це також робить дані більш однорідними, що полегшує задачу навчання алгоритму `SVN`.\n",
    "    - час розрахунку близько 13 секунд;\n",
    "    - точність близька до 0.89.\n",
    "\n",
    "\n",
    "3. Навчання за методом випадкового лісу показує кращу точність та набагато менший час навчання, оскільки це більш стійкий до шуму і невизначеності алгоритм. Метод випадкового лісу генерує декілька дерев рішень, і кожен з них голосує за класифікацію. Це дозволяє алгоритму випадкового лісу бути більш точним, ніж алгоритм `SVN`, який генерує лише одне дерево рішень. Крім того, метод випадкового лісу має набагато меншу кількість параметрів, ніж алгоритм `SVN`, що також сприяє його більш швидкому навчанню.\n",
    "    - час розрахунку близько 13 секунд;\n",
    "    - точність близька до 1.00.\n",
    "\n",
    "4. Навчання, де в якості ознак взяті статистичні ознаки запропоновані в [статті](https://www.sciencedirect.com/science/article/pii/S1877050916322153) [1], отримані по набору з 30 показників акселерометра для кожної осі $x$, $y$ та $z$ показує:\n",
    "    - точність моделі `SVM` значно підвищилась до значення 0.975, крім того час навчання значно зменшився і становить 46.9 ms.\n",
    "    - точність моделі `random forest` також підвищилась в порівнянні з навчанням на вихідних нормалізованих судячи з матриці помилок, також час навчання становить 766 ms, що значно менше ніж для навчання на вихідних нормалізованих даних, але натомість він на порядок вище в порявнянні з моделлю `SVN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблиця з результатами\n",
    "\n",
    "<center>\n",
    "<table>\n",
    "<caption>Таблиця. Результати</caption>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>Тип ознак</th>\n",
    "    <th>Алгоритм</th>\n",
    "    <th>Час розрахунку</th>\n",
    "    <th>Точність</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">вихідні нормалізовані</td>\n",
    "    <td>SVN</td>\n",
    "    <td>240 s</td>\n",
    "    <td>0.89</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Random Forest</td>\n",
    "    <td>13 s</td>\n",
    "    <td>~ 1.00</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">статистичні дані</td>\n",
    "    <td>SVN</td>\n",
    "    <td>46.9 ms</td>\n",
    "    <td>0.98</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Random Forest</td>\n",
    "    <td>766 ms</td>\n",
    "    <td>~ 1.00</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "Згідно таблиці, можна зробити висновок, що найкращі результати дає в сенсі час/чточність дає алгоритм `random forest`, який тренувався не на вихідних, а на статистичних ознаках. Ці висновки також підтверджуються аналізом матриці помилок, показує, що класифікатор `random forest` помиляється значно менше, ніж `SVM`. Використання статистичних даних, порівняно з сирими підвищує точність класифікації та знижує час навчання."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
